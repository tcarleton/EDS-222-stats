---
title: "EDS 222: Week 3: In-class Lab"
author: "{STUDENT NAME}"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
---

# Section 0: Setup

Load all the packages you need, plus our favorite `_common.R` source file.

```{r, echo = FALSE, eval = TRUE}
# You probably already have these packages installed, so let's just load them
library(tidyverse)
library(readr)
library(gt)
library(openintro)
library(ggplot2)
library(modelr)

options(scipen = 999) # disable scientific notation

# Set your file path here! Or, set this up as an .Rproj if you'd like.
rootdir <- ("~/Dropbox/Teaching/UCSB/EDS_222/EDS222_data")

# This runs the script _common.R, which loads all the packages we'll need for today and does some extra stuff we won't really use, at least for now.
source(file.path(rootdir,"labs","_common.R"))

# For labs, we want to see all our code
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1: Visualizing Scatterplots

Using similar concepts from a histogram or a density plot, we can use a scatter plot to visualize the relationship between two variables. It is **always** a good idea to look at a scatter plot when trying to establish the relationship between two variables. A scatter plot is a simple two-dimensional plot in which the two coordinates of each dot represent the values of two variables measured on a single observation. The **dependent** or response variable is typically on the vertical axis and the **independent** or explanatory variable on the horizontal axis.

Here we will use a data frame on possums and we will first try to see if (i) the total length of a possum is associated with the length of a possum's tail; (ii) the length of a possum's head is associated with the the length of possum's tail. Don't ask me why we might care about this, but I'm sure there are biologists who do! We just want some practice with `ggplot()`. 

The data are already loaded in `R`, and can be called using `data = possum`. Take a look at your variable names and make a scatter plot showing  (i) total length as a function of tail length and (ii) head length as a function of tail length. That is, treat tail length as your independent variable. 

1. Make the two scatter plots described above.
2. Discuss whether these two variables appear correlated, what sign you anticipate the correlation to be, and the strength of the correlation you expect.


```{r}

```

# Section 2: Calculating Correlations

Visualizing values of the correlation between two quantities from their scatter plot can be very difficult. Research has shown that people’s perception of the strength of these relationships can be influenced by design choices like the size of the graph and the aspect ratio,^[The _aspect ratio_ is the ratio of the width to the height of a figure or image.] among other features. Hence, to more objectively report the relationship between two variables, we use correlation, computing the "correlation coefficient" $r$.^[Note: we just called this "correlation" in lecture, but people use "correlation" and "correlation coefficient" interchangeably. In most cases, this refers to the Pearson's correlation coefficient, as defined in lecture. There are other forms of correlation that are less common, such as rank correlation, but we won't use them in this class.] Here, we will compute correlation coefficients for the two possum relationships plotted above.

**Exercise:**

1. Use the plots from section 1 to write your best estimate of the correlation coefficient between each of the two examples in section 1. 
  (i) the length of a possum's total length and the length of possum tail:
  (ii) the length of a possum's head and the length of possum tail:

2. Use the `cor()` function in `R` to calculate the correlation coefficient between the two variables in (i) and the two in (ii). How close was your guess to the true answer? 
```{r}
# (i) total & tail:

```



```{r, fig.margin=TRUE}
# (ii) head & tail:

```

# Section 3: Simple Linear Regression

## Perform Simple Linear Regression

To estimate the linear relationship between the variables explored above, we'll use `lm()` to fit a regression model using Ordinary Least Squares (OLS). The `lm()` function has two required arguments:

(i) a formula that indicates which variable is the dependent variable and which is the independent variable;
(ii) a data argument that identifies the data frame for the variables in (i).

First let's consider the relationship between total length and tail length. We assume there is a linear population relationship, specified as:

$$\text{possum total length} = \beta_0 + \beta_1 \text{possum tail length} + \epsilon$$

**Exercise:**

1. Use `lm()` to estimate $\hat\beta_0$ and $\hat\beta_1$ using this sample of data. Use `summary(lm())` or `gt()` to visualize the regression results.

2. Interpret your two coefficients, paying careful attention to units. 

3. Is your estimate of $\beta_0$ directly interpretable? What might you be concerned about when interpreting $\beta_0$? 

**Answers:**

```{r}

```

**Exercises, continued**

4. Does your model suggest anything about the relationship between tail length and body length^[Note that the "total" length is the sum of tail length plus body length.]? Why or why not? 

5. [If we have time] Repeat the above steps for the relationship between possum tail length and possum head length. Can you learn anything from directly comparing magnitudes of $\hat\beta_1$ across these two regressions?

```{r}

```

## Visualize Regression [if we have time]

Here, we visualize our simple linear regression models above using the scatter plots from Section 1.

**Exercise:** 

Use the `geom_smooth()` function with method argument set to `lm`, which stands for “linear model”, to add the best fit OLS line to your scatter plots from Section 1. Use the option `se = FALSE` to turn off estimates of uncertainty. Don't worry, we'll dig into those soon.

```{r}

```


```{r}

```

## Residuals, Sum of Squared Errors

The difference between what was observed in the data and what was predicted from the regression line is what we call an "error" or a “residual.” Observations that lie above the regression line exceeded their predicted value and have a _positive residual_. Observations that lie below the regression line are less than their predicted value and have a _negative residual_.

Recall that one of our assumptions needed in order to prove that OLS has the **lowest variance** of all unbiased estimators was that the population error $u$ is: normally distributed, has a mean of zero, and has constant variance. While these assumptions are not directly testable because we can never observe $u$, we can use our regression residuals $e$ to assess the plausibility of these assumptions in the population. 

**Exercise:**

Using the regression of total length on tail length:

1. Add to the `possum` dataframe a column of predicted total lengths $\hat y_i$ and a column of residuals $e_i = y_i-\hat y_i$.^[**Hint:** In `dplyr` you can use `add_predictions(mod)` where `mod` is a regression model to generate a new variable containing your model's predicted values.]

```{r}

```

2. Make a histogram of your residuals. Do they look approximately normally distributed?

```{r}

```

3. Compute the mean of your residuals. Is it basically zero?^[**Note:** OLS gives you this one for free. The OLS regression line will always go through the middle of your data, as it aims to minimize squared errors. So, you'll always end up with sample errors that are mean zero. This doesn't necessarily mean that in your population $u$ is mean zero!]

```{r}

```
4. Plot residuals against your independent variable, tail length. Does the variance look approximately constant across all values of tail length?

```{r}
 
```
